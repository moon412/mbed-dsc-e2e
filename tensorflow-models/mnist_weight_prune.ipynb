{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying weight pruning to CNN for MNIST\n",
    "* without pruning, protobuff can be converted by utensor-cli; with pruning, more nodes/ops like mask are in the graph_def, one error I got when using utensor-cli is `ValueError: unsupported op type in uTensor: QuantizedMul`\n",
    "* with pruning, a mask node is added with 0 and 1. The effective weights should be weights*mask=mask_weights. For example, `fc2_weights = sess.run(sess.graph.get_tensor_by_name(\"fc2/weights:0\"))`, `fc2_weights` won't be sparse. It will be multiplied by the corresponding mask. \n",
    "* Once the model is trained, it is necessary to remove the auxiliary variables (mask, threshold) and pruning ops added to the graph in the steps above. This can be accomplished using the strip_pruning_vars utility. This utility generates a binary GraphDef in which the variables have been converted to constants. In particular, the threshold variables are removed from the graph and the mask variable is fused with the corresponding weight tensor to produce a masked_weight tensor. This tensor is sparse, has the same size as the weight tensor, and the sparsity is as set by the target_sparsity or the weight_sparsity_map hyperparameters above. <br>\n",
    "`$ bazel build -c opt contrib/model_pruning:strip_pruning_vars` <br>\n",
    "`$ bazel-bin/contrib/model_pruning/strip_pruning_vars --checkpoint_dir=/path/to/checkpoints/ --output_node_names=graph_node1,graph_node2 --output_dir=/tmp --filename=pruning_stripped.pb`\n",
    "* with pruning, more weights are zeroout but the size of the tensor doens't change. So the size of the pb file won't change. But if the file is compressed (zipped), the size will reduce. \n",
    "* But will it work on uTensor? I don't think uTensor has programs to unzip compressed protobuff and special program to handle sparsed weights. I think it just load the weights normally into a matrix in RAM.. If the size of the weights doesn't change, the RAM usage will be the same as non-purned weights. Need to be confirmed. \n",
    "* NPU can process the compressed weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.model_pruning.python import pruning\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size, num_channels, num_classes = 28, 1, 10\n",
    "pooling_ksize = [1, 2, 2, 1]\n",
    "pooling_strides = [1, 2, 2, 1]\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size, img_size, num_channels], name='x')\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"x:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "<tf.Variable 'conv1/weights:0' shape=(5, 5, 1, 16) dtype=float32_ref>\n",
      "Tensor(\"conv1/conv_map:0\", shape=(?, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"conv1/activation:0\", shape=(?, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"max_pool1:0\", shape=(?, 14, 14, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('conv1') as scope:\n",
    "    kernel_shape = [5, 5, 1, 16]\n",
    "    strides = [1, 1, 1, 1]\n",
    "    bias_shape = kernel_shape[-1]\n",
    "    kernel = tf.get_variable(\"weights\", shape=kernel_shape, initializer=tf.contrib.layers.xavier_initializer_conv2d(), \n",
    "                             dtype=tf.float32, trainable=True)\n",
    "    conv = tf.nn.conv2d(x, pruning.apply_mask(kernel, scope), strides=strides, padding=\"SAME\", name=\"conv_map\")\n",
    "    bias = tf.get_variable(\"bias\", shape=bias_shape, initializer=tf.contrib.layers.xavier_initializer(), \n",
    "                           dtype=tf.float32, trainable=True)\n",
    "    pre_activation = tf.add(conv, bias)\n",
    "    conv1 = tf.nn.relu(pre_activation, name=\"activation\")\n",
    "\n",
    "\n",
    "pool1 = tf.nn.max_pool(value=conv1, ksize=pooling_ksize, strides=pooling_strides, padding=\"SAME\", name=\"max_pool1\")\n",
    "\n",
    "print(x)\n",
    "print(kernel)\n",
    "print(conv)\n",
    "print(conv1)\n",
    "print(pool1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv2/weights:0' shape=(5, 5, 16, 32) dtype=float32_ref>\n",
      "Tensor(\"conv2/conv_map:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"conv2/relu:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"max_pooling2:0\", shape=(?, 7, 7, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"conv2\") as scope:\n",
    "    kernel_shape = [5, 5, 16, 32]\n",
    "    strides = [1, 1, 1, 1]\n",
    "    bias_shape = kernel_shape[-1]\n",
    "    kernel = tf.get_variable(name=\"weights\", shape=kernel_shape, dtype=tf.float32,\n",
    "                             initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "    conv = tf.nn.conv2d(input=pool1, filters=pruning.apply_mask(kernel, scope), strides=strides, padding=\"SAME\", name='conv_map')\n",
    "    bias = tf.get_variable(name=\"bias\", shape=bias_shape, dtype=tf.float32,\n",
    "                           initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "    pre_activation = tf.add(conv, bias)\n",
    "    conv2 = tf.nn.relu(pre_activation, name=\"relu\")\n",
    "\n",
    "pool2 = tf.nn.max_pool(value=conv2, ksize=pooling_ksize, strides=pooling_strides, padding=\"SAME\", name=\"max_pooling2\")\n",
    "\n",
    "print(kernel)\n",
    "print(conv)\n",
    "print(conv2)\n",
    "print(pool2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv3/weights:0' shape=(5, 5, 32, 64) dtype=float32_ref>\n",
      "Tensor(\"conv3/conv_map:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"conv3/relu:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"max_pooling3:0\", shape=(?, 4, 4, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"conv3\") as scope:\n",
    "    kernel_shape = [5, 5, 32, 64]\n",
    "    strides = [1, 1, 1, 1]\n",
    "    bias_shape = kernel_shape[-1]\n",
    "    kernel = tf.get_variable(name=\"weights\", shape=kernel_shape, dtype=tf.float32,\n",
    "                             initializer=tf.contrib.layers.xavier_initializer_conv2d(), trainable=True)\n",
    "    conv = tf.nn.conv2d(input=pool2, filters=pruning.apply_mask(kernel), strides=strides, padding=\"SAME\", name=\"conv_map\")\n",
    "    bias = tf.get_variable(name=\"bias\", shape=bias_shape, dtype=tf.float32,\n",
    "                           initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "    pre_activation = tf.add(conv, bias)\n",
    "    conv3 = tf.nn.relu(pre_activation, name=\"relu\")\n",
    "\n",
    "pool3 = tf.nn.max_pool(value=conv3, ksize=pooling_ksize, strides=pooling_strides, padding=\"SAME\", name=\"max_pooling3\")\n",
    "\n",
    "print(kernel)\n",
    "print(conv)\n",
    "print(conv3)\n",
    "print(pool3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"flatten:0\", shape=(?, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pool3_shape = pool3.shape.as_list()\n",
    "pool3_flat = tf.reshape(pool3, [-1, pool3_shape[1]*pool3_shape[2]*pool3_shape[3]], name=\"flatten\")\n",
    "print(pool3_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 1024]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool3_flat.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool3_flat.get_shape()[1].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'fc1/weights:0' shape=(1024, 128) dtype=float32_ref>\n",
      "Tensor(\"fc1/relu:0\", shape=(?, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"fc1\") as scope:\n",
    "    weights_shape = [pool3_flat.shape.as_list()[1], 128]\n",
    "    bias_shape = weights_shape[-1]\n",
    "    weights = tf.get_variable(name=\"weights\", shape=weights_shape, dtype=tf.float32,\n",
    "                              initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "    bias = tf.get_variable(name=\"bias\", shape=bias_shape, dtype=tf.float32,\n",
    "                           initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "    fc = tf.matmul(pool3_flat, pruning.apply_mask(weights, scope), name=\"matmul\")\n",
    "    pre_activation = tf.add(fc, bias)\n",
    "    fc1 = tf.nn.relu(fc, name=\"relu\")\n",
    "\n",
    "print(weights)\n",
    "print(fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'fc2/weights:0' shape=(128, 10) dtype=float32_ref>\n",
      "Tensor(\"fc2/logits:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"fc2/y_pred:0\", shape=(?,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"fc2\") as scope:\n",
    "    weights_shape = [fc1.get_shape()[1].value, num_classes]\n",
    "    bias_shape = weights_shape[-1]\n",
    "    weights = tf.get_variable(name=\"weights\", shape=weights_shape, dtype=tf.float32,\n",
    "                              initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "    bias = tf.get_variable(name=\"bias\", shape=bias_shape, dtype=tf.float32,\n",
    "                           initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "    fc = tf.matmul(fc1, pruning.apply_mask(weights), name=\"matmul\")\n",
    "    logits = tf.add(fc, bias, name=\"logits\")\n",
    "    y_pred = tf.argmax(logits, axis=1, name=\"y_pred\")\n",
    "\n",
    "print(weights)\n",
    "print(logits)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.contrib.framework.get_or_create_global_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Loss\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, \n",
    "                                                               logits=logits)\n",
    "    loss = tf.reduce_mean(cross_entropy, name=\"cross_entropy_loss\")\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss, global_step=global_step, name=\"train_step\")\n",
    "  \n",
    "# Here we specify the output as \"Prediction/y_pred\", this will be important later\n",
    "with tf.name_scope(\"Prediction\"): \n",
    "    correct_prediction = tf.equal(y_pred, \n",
    "                                  tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Loss/softmax_cross_entropy_with_logits/Reshape_2:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"Loss/cross_entropy_loss:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Prediction/accuracy:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(cross_entropy)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n",
      "1100\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "n_epochs = 2\n",
    "n_batches = int(mnist.train.num_examples / batch_size)\n",
    "end_step = n_epochs * n_batches\n",
    "print(n_batches)\n",
    "print(end_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name=model_pruning,begin_pruning_step=0,end_pruning_step=-1,weight_sparsity_map=[''],threshold_decay=0.0,pruning_frequency=10,nbins=256,block_height=1,block_width=1,block_pooling_function=AVG,initial_sparsity=0.0,target_sparsity=0.5,sparsity_function_begin_step=0,sparsity_function_end_step=100,sparsity_function_exponent=3.0,use_tpu=False\n"
     ]
    }
   ],
   "source": [
    "pruning_hparams = pruning.get_pruning_hparams()\n",
    "print(pruning_hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_hparams.begin_pruning_step = 0\n",
    "pruning_hparams.end_pruning_step = end_step\n",
    "pruning_hparams.frequency = 100\n",
    "pruning_hparams.target_sparsity = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Updating masks.\n"
     ]
    }
   ],
   "source": [
    "pruning_obj = pruning.Pruning(pruning_hparams, global_step=global_step)\n",
    "make_update_op = pruning_obj.conditional_mask_update_op()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss: 2.34491, training accuracy: 0.103909\n",
      "Epoch 0, validation loss: 2.34243, validation accuracy 0.11\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy = sess.run([loss, accuracy], \n",
    "                                      feed_dict={x: mnist.train.images.reshape(mnist.train.num_examples, img_size, img_size, num_channels), \n",
    "                                                 y_: mnist.train.labels})\n",
    "print('Epoch %d, training loss: %g, training accuracy: %g' % (0, train_loss, train_accuracy))\n",
    "val_loss, val_accuracy = sess.run([loss, accuracy], \n",
    "                                  feed_dict={x: mnist.validation.images.reshape(mnist.validation.num_examples, img_size, img_size, num_channels),\n",
    "                                             y_: mnist.validation.labels})\n",
    "print('Epoch %d, validation loss: %g, validation accuracy %g' % (0, val_loss, val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight sparsities:  [0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Weight sparsities: \", sess.run(tf.contrib.model_pruning.get_weight_sparsity()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss: 1.46961, training accuracy: 0.619109\n",
      "Epoch 0, validation loss: 1.45551, validation accuracy 0.6352\n",
      "Weight sparsity:  [0.9, 0.9, 0.9, 0.9000015, 0.90000004]\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_epochs):\n",
    "    for j in range(n_batches):\n",
    "        batch_images, batch_labels = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_step, feed_dict={x: batch_images.reshape(batch_size, img_size, img_size, num_channels), \n",
    "                                        y_: batch_labels})\n",
    "        sess.run(make_update_op)\n",
    "    if i % 2 == 0:\n",
    "        train_loss, train_accuracy = sess.run([loss, accuracy], \n",
    "                                              feed_dict={x: mnist.train.images.reshape(mnist.train.num_examples, img_size, img_size, num_channels), \n",
    "                                                         y_: mnist.train.labels})\n",
    "        print('Epoch %d, training loss: %g, training accuracy: %g' % (i, train_loss, train_accuracy))\n",
    "        val_loss, val_accuracy = sess.run([loss, accuracy], \n",
    "                                          feed_dict={x: mnist.validation.images.reshape(mnist.validation.num_examples, img_size, img_size, num_channels),\n",
    "                                                     y_: mnist.validation.labels})\n",
    "        print('Epoch %d, validation loss: %g, validation accuracy %g' % (i, val_loss, val_accuracy))\n",
    "        print(\"Weight sparsity: \", sess.run(tf.contrib.model_pruning.get_weight_sparsity()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.7616\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy %g' % sess.run(accuracy, \n",
    "                                    feed_dict={x: mnist.validation.images.reshape(mnist.validation.num_examples, img_size, img_size, num_channels), \n",
    "                                               y_: mnist.validation.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./chkps_mnist_weight_prune/mnist_prune'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, './chkps_mnist_weight_prune/mnist_prune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.graph_util import remove_training_nodes\n",
    "from tensorflow.tools.graph_transforms import TransformGraph\n",
    "sub_graph_def = remove_training_nodes(sess.graph_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fc2/y_pred']\n"
     ]
    }
   ],
   "source": [
    "output_nodes_list = [sess.graph.get_operation_by_name(\"fc2/y_pred\").name]\n",
    "print(output_nodes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 14 variables.\n",
      "INFO:tensorflow:Converted 14 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import graph_util as gu\n",
    "sub_graph_def = gu.convert_variables_to_constants(sess=sess, \n",
    "                                                  input_graph_def=sub_graph_def,\n",
    "                                                  output_node_names=output_nodes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x',\n",
       " 'conv1/weights',\n",
       " 'conv1/mask',\n",
       " 'conv1/weights/masked_weight',\n",
       " 'conv1/conv_map',\n",
       " 'conv1/bias',\n",
       " 'conv1/Add',\n",
       " 'conv1/activation',\n",
       " 'max_pool1',\n",
       " 'conv2/weights',\n",
       " 'conv2/mask',\n",
       " 'conv2/weights/masked_weight',\n",
       " 'conv2/conv_map',\n",
       " 'conv2/bias',\n",
       " 'conv2/Add',\n",
       " 'conv2/relu',\n",
       " 'max_pooling2',\n",
       " 'conv3/weights',\n",
       " 'conv3//mask',\n",
       " 'conv3/weights/masked_weight',\n",
       " 'conv3/conv_map',\n",
       " 'conv3/bias',\n",
       " 'conv3/Add',\n",
       " 'conv3/relu',\n",
       " 'max_pooling3',\n",
       " 'flatten/shape',\n",
       " 'flatten',\n",
       " 'fc1/weights',\n",
       " 'fc1/mask',\n",
       " 'fc1/weights/masked_weight',\n",
       " 'fc1/matmul',\n",
       " 'fc1/relu',\n",
       " 'fc2/weights',\n",
       " 'fc2/bias',\n",
       " 'fc2//mask',\n",
       " 'fc2/weights/masked_weight',\n",
       " 'fc2/matmul',\n",
       " 'fc2/logits',\n",
       " 'fc2/y_pred/dimension',\n",
       " 'fc2/y_pred']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[node.name for node in sub_graph_def.node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./mnist_cnn_0to9/mnist_cnn_weight_prune.pb'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.write_graph(sub_graph_def, \"./mnist_cnn_0to9\", \"mnist_cnn_weight_prune.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1113\n"
     ]
    }
   ],
   "source": [
    "all_tensors = [op.values() for op in sess.graph.get_operations()]\n",
    "print(len(all_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor 'x:0' shape=(?, 28, 28, 1) dtype=float32>,),\n",
       " (<tf.Tensor 'conv3/bias/Assign:0' shape=(64,) dtype=float32_ref>,),\n",
       " (<tf.Tensor 'Loss/softmax_cross_entropy_with_logits/concat_1/values_0:0' shape=(1,) dtype=int32>,),\n",
       " (<tf.Tensor 'gradients/conv3/weights/masked_weight_grad/Mul_1:0' shape=(5, 5, 32, 64) dtype=float32>,),\n",
       " (<tf.Tensor 'conv3/weights/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,),\n",
       " (<tf.Tensor 'model_pruning_2/LogicalOr:0' shape=() dtype=bool>,),\n",
       " (<tf.Tensor 'cond/model_pruning/conv3//mask_assign/Switch:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
       "  <tf.Tensor 'cond/model_pruning/conv3//mask_assign/Switch:1' shape=(5, 5, 32, 64) dtype=float32_ref>),\n",
       " (<tf.Tensor 'save/Assign_20:0' shape=(64,) dtype=float32_ref>,),\n",
       " (<tf.Tensor 'zero_fraction_2/fraction:0' shape=() dtype=float32>,),\n",
       " (<tf.Tensor 'zero_fraction_6/counts_to_fraction/sub:0' shape=() dtype=int64>,),\n",
       " (<tf.Tensor 'zero_fraction_10/cond/count_nonzero_1/Cast:0' shape=(5, 5, 1, 16) dtype=int64>,),\n",
       " (<tf.Tensor 'zero_fraction_14/cond/Cast:0' shape=() dtype=int64>,)]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tensors[::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2_weights = sess.run(sess.graph.get_tensor_by_name(\"fc2/weights:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 10)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fc2_weights == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9, 0.9, 0.9, 0.9000015, 0.90000004]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.contrib.model_pruning.get_weight_sparsity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_nas]",
   "language": "python",
   "name": "conda-env-tf_nas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
