{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is based on:\n",
    "# https://www.tensorflow.org/get_started/mnist/pros\n",
    "\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.framework import graph_util as gu\n",
    "from tensorflow.python.framework.graph_util import remove_training_nodes\n",
    "import json\n",
    "#from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "# Load the test data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size, num_channels, num_classes = 28, 1, 10\n",
    "\n",
    "pooling_ksize = [1, 2, 2, 1]\n",
    "pooling_strides = [1, 2, 2, 1]\n",
    "kernel_shape_1 = [5, 5, 1, 16]\n",
    "bias_shape_1 = [16]\n",
    "kernel_shape_2 = [5, 5, 16, 32]\n",
    "bias_shape_2 = [32]\n",
    "kernel_shape_3 = [5, 5, 32, 64]\n",
    "bias_shape_3 = [64]\n",
    "fc_neuron_1 = 128\n",
    "\n",
    "batch_size = 50\n",
    "n_epochs = 2\n",
    "n_batches = int(mnist.train.num_examples / batch_size)\n",
    "display_step = 10\n",
    "\n",
    "save_ckps_dir = \"./saved_models/chkps_mnist_cnn/\"\n",
    "save_pb_dir = \"./saved_models/pb_mnist_cnn/\"\n",
    "chkp_fd_name = \"chkp_config1/mnist_cnn\"\n",
    "pb_file_name = \"mnist_cnn_config1.pb\"\n",
    "training_dir = \"./training_logs/\"\n",
    "config_file_name = \"training_config1.json\"\n",
    "result_file_name = \"training_log1.json\"\n",
    "\n",
    "config = {\"pooling_ksize\": pooling_ksize,\n",
    "          \"pooling_strides\": pooling_strides,\n",
    "          \"kernel_shape\": [kernel_shape_1, kernel_shape_2, kernel_shape_3],\n",
    "          \"fc_shape\": [fc_neuron_1],\n",
    "          \"batch_size\": batch_size, \n",
    "          \"n_epochs\": n_epochs}\n",
    "results = {\"init_loss\": [], \"init_acc\": [],\n",
    "           \"val_loss\": [], \"val_acc\": [],\n",
    "           \"train_loss\": [], \"train_acc\": [],\n",
    "           \"test_loss\": [], \"test_acc\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size, img_size, num_channels], name='x')\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"x:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "<tf.Variable 'covn1/weights:0' shape=(5, 5, 1, 16) dtype=float32_ref>\n",
      "Tensor(\"covn1/conv_map:0\", shape=(?, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"covn1/relu:0\", shape=(?, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"max_pool1:0\", shape=(?, 14, 14, 16), dtype=float32)\n",
      "<tf.Variable 'conv2/weights:0' shape=(5, 5, 16, 32) dtype=float32_ref>\n",
      "Tensor(\"conv2/conv_map:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"conv2/relu:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"max_pool2:0\", shape=(?, 7, 7, 32), dtype=float32)\n",
      "<tf.Variable 'conv3/weights:0' shape=(5, 5, 32, 64) dtype=float32_ref>\n",
      "Tensor(\"conv3/conv_map:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"conv3/relu:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"max_pool3:0\", shape=(?, 4, 4, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"covn1\") as scope:\n",
    "    kernel = tf.get_variable(name=\"weights\", shape=kernel_shape_1, dtype=tf.float32,\n",
    "                              initializer=tf.contrib.layers.xavier_initializer_conv2d(), trainable=True)\n",
    "    bias = tf.get_variable(name=\"bias\", shape=bias_shape_1, dtype=tf.float32,\n",
    "                           initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "    conv = tf.nn.conv2d(x, filters=kernel, strides=[1, 1, 1, 1], padding=\"SAME\", name=\"conv_map\")\n",
    "    pre_activation = tf.add(conv, bias)\n",
    "    conv1 = tf.nn.relu(pre_activation, name=\"relu\")\n",
    "\n",
    "pool1 = tf.nn.max_pool(conv1, ksize=pooling_ksize, strides=pooling_strides, padding=\"SAME\", name=\"max_pool1\")\n",
    "print(x)\n",
    "print(kernel)\n",
    "print(conv)\n",
    "print(conv1)\n",
    "print(pool1)\n",
    "\n",
    "with tf.variable_scope(\"conv2\") as scope:\n",
    "    kernel = tf.get_variable(name=\"weights\", shape=kernel_shape_2, dtype=tf.float32,\n",
    "                             initializer=tf.contrib.layers.xavier_initializer_conv2d(), trainable=True)\n",
    "    bias = tf.get_variable(name=\"bias\", shape=bias_shape_2, dtype=tf.float32,\n",
    "                           initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "    conv = tf.nn.conv2d(pool1, kernel, strides=[1, 1, 1, 1], padding=\"SAME\", name=\"conv_map\")\n",
    "    pre_activation = tf.add(conv, bias)\n",
    "    conv2 = tf.nn.relu(pre_activation, name=\"relu\")\n",
    "\n",
    "pool2 = tf.nn.max_pool(conv2, ksize=pooling_ksize, strides=pooling_strides, padding=\"SAME\", name=\"max_pool2\")\n",
    "print(kernel)\n",
    "print(conv)\n",
    "print(conv2)\n",
    "print(pool2)\n",
    "\n",
    "with tf.variable_scope(\"conv3\") as scope:\n",
    "    kernel = tf.get_variable(name=\"weights\", shape=kernel_shape_3, dtype=tf.float32,\n",
    "                             initializer=tf.contrib.layers.xavier_initializer_conv2d(), trainable=True)\n",
    "    bias = tf.get_variable(name=\"bias\", shape=bias_shape_3, dtype=tf.float32,\n",
    "                           initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "    conv = tf.nn.conv2d(pool2, kernel, strides=[1, 1, 1, 1], padding=\"SAME\", name=\"conv_map\")\n",
    "    pre_activation = tf.add(conv, bias)\n",
    "    conv3 = tf.nn.relu(pre_activation, name=\"relu\")\n",
    "\n",
    "pool3 = tf.nn.max_pool(conv3, ksize=pooling_ksize, strides=pooling_strides, padding=\"SAME\", name=\"max_pool3\")\n",
    "print(kernel)\n",
    "print(conv)\n",
    "print(conv3)\n",
    "print(pool3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool3_flat = tf.reshape(pool3, [-1, pool3.get_shape()[1]*pool3.get_shape()[2]*pool3.get_shape()[3]], name=\"flatten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"flatten:0\", shape=(?, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(pool3_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'fc1/weights:0' shape=(1024, 128) dtype=float32_ref>\n",
      "Tensor(\"fc1/relu:0\", shape=(?, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"fc1\") as scope:\n",
    "    weights = tf.get_variable(name=\"weights\", shape=[pool3_flat.get_shape()[1], fc_neuron_1], dtype=tf.float32,\n",
    "                              initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "    bias = tf.get_variable(name=\"bias\", shape=[fc_neuron_1], dtype=tf.float32,\n",
    "                           initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "    fc = tf.matmul(pool3_flat, weights, name=\"matmul\")\n",
    "    pre_activation = tf.add(fc, bias)\n",
    "    fc1 = tf.nn.relu(pre_activation, name=\"relu\")\n",
    "\n",
    "print(weights)\n",
    "print(fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'fc2/weights:0' shape=(128, 10) dtype=float32_ref>\n",
      "Tensor(\"fc2/logits:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"fc2/y_pred:0\", shape=(?,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"fc2\") as scope:\n",
    "    weights = tf.get_variable(name=\"weights\", shape=[fc_neuron_1, num_classes], dtype=tf.float32,\n",
    "                              initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "    bias = tf.get_variable(name=\"bias\", shape=[num_classes], dtype=tf.float32,\n",
    "                           initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "    fc = tf.matmul(fc1, weights, name=\"matmul\")\n",
    "    logits = tf.add(fc, bias, name=\"logits\")\n",
    "    y_pred = tf.argmax(logits, axis=1, name=\"y_pred\")\n",
    "\n",
    "print(weights)\n",
    "print(logits)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"loss/cross_entropy/Reshape_2:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"loss/cross_entropy_loss:0\", shape=(), dtype=float32)\n",
      "name: \"loss/train_step\"\n",
      "op: \"NoOp\"\n",
      "input: \"^loss/train_step/update_covn1/weights/ApplyAdam\"\n",
      "input: \"^loss/train_step/update_covn1/bias/ApplyAdam\"\n",
      "input: \"^loss/train_step/update_conv2/weights/ApplyAdam\"\n",
      "input: \"^loss/train_step/update_conv2/bias/ApplyAdam\"\n",
      "input: \"^loss/train_step/update_conv3/weights/ApplyAdam\"\n",
      "input: \"^loss/train_step/update_conv3/bias/ApplyAdam\"\n",
      "input: \"^loss/train_step/update_fc1/weights/ApplyAdam\"\n",
      "input: \"^loss/train_step/update_fc1/bias/ApplyAdam\"\n",
      "input: \"^loss/train_step/update_fc2/weights/ApplyAdam\"\n",
      "input: \"^loss/train_step/update_fc2/bias/ApplyAdam\"\n",
      "input: \"^loss/train_step/Assign\"\n",
      "input: \"^loss/train_step/Assign_1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=logits, name=\"cross_entropy\")\n",
    "    loss = tf.reduce_mean(cross_entropy, name=\"cross_entropy_loss\")\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(loss, name=\"train_step\")\n",
    "print(cross_entropy)\n",
    "print(loss)\n",
    "print(train_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"eval/Equal:0\", shape=(?,), dtype=bool)\n",
      "Tensor(\"eval/accuracy:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.equal(y_pred, tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "print(correct)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss: 0.173582, training accuracy: 0.946818\n",
      "Epoch 0, validation loss: 0.16284, validation accuracy 0.9522\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy = sess.run([loss, accuracy], \n",
    "                                      feed_dict={x: mnist.train.images.reshape(mnist.train.num_examples, img_size, img_size, num_channels), \n",
    "                                                 y_: mnist.train.labels})\n",
    "print('Epoch %d, training loss: %g, training accuracy: %g' % (0, train_loss, train_accuracy))\n",
    "val_loss, val_accuracy = sess.run([loss, accuracy], \n",
    "                                  feed_dict={x: mnist.validation.images.reshape(mnist.validation.num_examples, img_size, img_size, num_channels),\n",
    "                                             y_: mnist.validation.labels})\n",
    "print('Epoch %d, validation loss: %g, validation accuracy %g' % (0, val_loss, val_accuracy))\n",
    "results[\"init_loss\"].append(val_loss)\n",
    "results[\"init_acc\"].append(val_accuracy)\n",
    "max_accuracy = val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the current model!\n",
      "Save the current model!\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_epochs):\n",
    "    for j in range(n_batches):\n",
    "        batch_images, batch_labels = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_step, feed_dict={x: batch_images.reshape(batch_size, img_size, img_size, num_channels), \n",
    "                                        y_: batch_labels})\n",
    "        \n",
    "    train_loss, train_accuracy = sess.run([loss, accuracy], \n",
    "                                          feed_dict={x: mnist.train.images.reshape(mnist.train.num_examples, img_size, img_size, num_channels), \n",
    "                                                     y_: mnist.train.labels})\n",
    "    results[\"train_loss\"].append(train_loss)\n",
    "    results[\"train_acc\"].append(train_accuracy)\n",
    "\n",
    "    val_loss, val_accuracy = sess.run([loss, accuracy], \n",
    "                                      feed_dict={x: mnist.validation.images.reshape(mnist.validation.num_examples, img_size, img_size, num_channels),\n",
    "                                                 y_: mnist.validation.labels})\n",
    "    results[\"val_loss\"].append(val_loss)\n",
    "    results[\"val_acc\"].append(val_accuracy)\n",
    "    \n",
    "    if val_accuracy > max_accuracy:\n",
    "        print(\"Save the current model!\")\n",
    "        max_accuracy = val_accuracy\n",
    "        saver.save(sess, save_ckps_dir + chkp_fd_name)\n",
    "    \n",
    "    if (i+1) % display_step == 0:\n",
    "        print('Epoch %d, training loss: %g, training accuracy: %g' % (i, train_loss, train_accuracy))\n",
    "        print('Epoch %d, validation loss: %g, validation accuracy %g' % (i, val_loss, val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9819\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy =  sess.run([loss, accuracy], \n",
    "                                     feed_dict={x: mnist.test.images.reshape(mnist.test.num_examples, img_size, img_size, num_channels), \n",
    "                                                y_: mnist.test.labels})\n",
    "results[\"test_loss\"].append(test_loss)\n",
    "results[\"test_acc\"].append(test_accuracy)\n",
    "print(\"Test accuracy: %g\" % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fc2/y_pred']\n"
     ]
    }
   ],
   "source": [
    "#saver.save(sess, \"./chkps/mnist_cnn\")\n",
    "out_nodes = [y_pred.op.name]\n",
    "print(out_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saver.restore(sess, \"./chkps/mnist_cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_graph_def = remove_training_nodes(sess.graph_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_graph_def = gu.convert_variables_to_constants(sess, sub_graph_def, out_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written graph to: ./saved_models/pb_mnist_cnn/mnist_cnn_config1.pb\n"
     ]
    }
   ],
   "source": [
    "graph_path = tf.train.write_graph(sub_graph_def,\n",
    "                                  save_pb_dir,\n",
    "                                  pb_file_name,\n",
    "                                  as_text=False)\n",
    "\n",
    "print('written graph to: %s' % graph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pooling_ksize': [1, 2, 2, 1],\n",
       " 'pooling_strides': [1, 2, 2, 1],\n",
       " 'kernel_shape': [[5, 5, 1, 16], [5, 5, 16, 32], [5, 5, 32, 64]],\n",
       " 'fc_shape': [128],\n",
       " 'batch_size': 50,\n",
       " 'n_epochs': 2}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'init_loss': [0.16283987],\n",
       " 'init_acc': [0.9522],\n",
       " 'val_loss': [0.108026855, 0.07855901, 0.068353906],\n",
       " 'val_acc': [0.9652, 0.975, 0.981],\n",
       " 'train_loss': [0.111411236, 0.0780043, 0.0683312],\n",
       " 'train_acc': [0.96605456, 0.976, 0.97865456],\n",
       " 'test_loss': [0.061097186],\n",
       " 'test_acc': [0.9819]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_dir+config_file_name, 'w') as f:\n",
    "    json.dump(config, f)\n",
    "\n",
    "with open(training_dir+result_file_name, 'w') as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_cpu]",
   "language": "python",
   "name": "conda-env-tensorflow_cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
